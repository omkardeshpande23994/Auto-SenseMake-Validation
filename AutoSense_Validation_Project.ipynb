{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Sense Making and Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task A, I have used text classifiers models from scikit-learn for validation of data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Imports : \n",
    "\n",
    "For imports, I have used 3 main libraries :\n",
    "1. **Numpy** - For numpy arrays to process with Scikit Learn\n",
    "2. **Pandas** - Pandas Dataframes for reading and data manupulation\n",
    "3. **Scikit-Learn** - For implementation of text classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt2\n",
    "from matplotlib.pyplot import xticks\n",
    "from nltk.classify.decisiontree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Handling :\n",
    "\n",
    "Here, I have read the CSV training as well as test(Trial) files along with their labels and transformed the minto pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = \"/Training  Data/Training  Data/\"\n",
    "testPath = \"Trial Data/Trial Data/\"\n",
    "\n",
    "trainDatadf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskA_data_all.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trainLabeldf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskA_answers_all.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "trialDatadf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskA_trial_data.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trialLabeldf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskA_trial_answer.csv\", encoding=\"utf-8\", header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the train and test labels came without a column name, We are renaming them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabeldf.rename(columns={0: \"id\", 1: \"label\"}, inplace=True)\n",
    "trialLabeldf.rename(columns={0: \"id\", 1: \"label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels given in the training and test datasets are inversed.  \n",
    "i.e. : the labels are showing non-sensical statement instead of correct ones, So we will **inverse** the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverting train labels\n",
    "trainLabeldf[\"label\"] = ~(trainLabeldf[\"label\"].astype(\"bool\"))\n",
    "trainLabeldf[\"label\"] = trainLabeldf[\"label\"].astype(\"int\")\n",
    "\n",
    "# inverting test labels\n",
    "trialLabeldf[\"label\"] = ~(trialLabeldf[\"label\"].astype(\"bool\"))\n",
    "trialLabeldf[\"label\"] = trialLabeldf[\"label\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We will combine the train data and train labels for better manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge label and data\n",
    "trainDatadf = trainDatadf.merge(trainLabeldf, on=\"id\")\n",
    "trialDatadf = trialDatadf.merge(trialLabeldf, on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the newly created combined dataframe, We will check the correct sentence   \n",
    "and create a different copy with a list of correct statements which will be our features for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking correct data\n",
    "correctData = []\n",
    "correctLabel = []\n",
    "\n",
    "for index, row in trainDatadf.iterrows():\n",
    "    if row[\"label\"] == 1:\n",
    "        correctData.append(str(row[\"sent1\"]))\n",
    "        correctLabel.append(row[\"label\"])\n",
    "       \n",
    "    elif row[\"label\"] == 0:\n",
    "        correctData.append(str(row[\"sent0\"]))\n",
    "        correctLabel.append(row[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the test data, We will follow a similar stratergy by creating two copies of test dataframe.  \n",
    "1. Correct Data\n",
    "2. Wrong Data  \n",
    "  \n",
    "and we will combine the two into a single numpy array which is then passed to the model.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctDataTrial = []\n",
    "wrongtDataTrial = []\n",
    "correctTrialLabel = []\n",
    "wrongTrialLabel = []\n",
    "for index, row in trialDatadf.iterrows():\n",
    "    if row[\"label\"] == 1:\n",
    "        correctDataTrial.append(str(row[\"sent1\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"sent0\"]))\n",
    "        wrongTrialLabel.append(row[\"label\"])\n",
    "\n",
    "    elif row[\"label\"] == 0:\n",
    "        correctDataTrial.append(str(row[\"sent0\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"sent1\"]))\n",
    "        wrongTrialLabel.append(row[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are flattening the numpy array for both train and test data into a single 1D array as the model doesnt take multidimensional array for input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = np.array([*correctData]).flatten()\n",
    "TrainLabel = np.array([*correctLabel]).flatten()\n",
    "\n",
    "TestData = np.array([*correctDataTrial, *wrongtDataTrial]).flatten()\n",
    "TestLabel = np.array([*correctTrialLabel, *wrongTrialLabel]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the current data present in the dataframes are in sentence form, We have to convert them into numeric features which can be fed to the model.  \n",
    "There are several steps to be done here :    \n",
    "**1. Text Preprocessing**\n",
    "   - Converting text to lowercase letters  \n",
    "   - Removal of punctuation and special characters  \n",
    "   - Stemming/Lemmatization  \n",
    "   - Stop word removal \n",
    "     \n",
    "**2. Tokenization**  \n",
    "**3. Feature Extraction**  \n",
    "    \n",
    "All these steps can be done using different vectorizer models such as :    \n",
    "CountVectorizer, Bag of Words, CBOW, TF-IDF Vectorizer, etc.  \n",
    "  \n",
    "Here, We have used TF-IDF Vectorizer which better than most of the models.  \n",
    "  \n",
    "**Why TF-IDF?**  \n",
    "Because CountVectorizer or BOW will generally return the occurrences of words that can detrimental to your performance if your text has a lot of common words that can overcome the count of important topics in the text.  \n",
    "TF-IDF Vectorizer balances out the Term frequncy(which is occurrence) with the Inverse Document Frequency (How often the words appear across the dataset)\n",
    "So it provides a better score for tokenized words.  \n",
    "  \n",
    "**What does it do?**  \n",
    "TF-IDF Vectorizer performs all the preprocessing steps necessary for obtaining a cleaner data structure (lowercase, stopwords, etc.)  \n",
    "There is a different range of parameters that help us tweak the performance of TF-IDF.  \n",
    "Here, I have used lowercase (Auto), Stop word removal and N-gram from 1 to 3 to build a dictionary of n-grams to help improve the accuracy.  \n",
    "I have also defined max features as our matrix is very sparse.   \n",
    "This vectorizer tokenizes the words and creates a set of features for each sentence on a word level.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\", ngram_range=(1, 3), max_features=18686\n",
    ")\n",
    "\n",
    "#Fit the train data\n",
    "X = vectorizer.fit_transform(TrainData).toarray()\n",
    "\n",
    "#Fit the test data\n",
    "Xtest = vectorizer.fit_transform(TestData).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classifier models, I have used different models to compare the accuracy between the classifiers. \n",
    "  \n",
    "**- Multinomial Naive Bayes**  \n",
    "**- Gaussian Naive Bayes**  \n",
    "**- Random Forest Classifier**   \n",
    "**- KNN Algorithm**  \n",
    "**- SVM**  \n",
    "**- LDA**  \n",
    "**- Decision Tree Classifier**  \n",
    "\n",
    "  \n",
    "### Multinomial Naive Bayes  \n",
    "Naive Bayes algorithm checks the conditional independence of each feature concerning the rest of the features.  \n",
    "Multinomial Naive Bayes is one of the categories in the Naive Bayes algorithm which specifies the type of distribution (Multinomial) for each of the features.  \n",
    "Multinomial distribution can be said as distribution covered over n number of independent experiments which provides a discrete number of possible outputs.  \n",
    "  \n",
    "### Gaussian Naive Bayes  \n",
    "Gaussian Naive Bayes is the simplest Naive Bayes model.  \n",
    "Gaussian distribution basically continuous probability distribution.  \n",
    "This algorithm checks the independence of each feature w.r.t its continuous distribution and provides the classification according to such distribution.  \n",
    "\n",
    "### Random Forest Classifier  \n",
    "Random Forest Classifier is an ensemble-based classification method that uses multiple ML models to predict better accuracy and performance than a single model.  \n",
    "RFC operates by constructing multiple decision trees and provides a mean classification amongst the trees.  \n",
    "Because of mean, RFC  prevents overfitting of training data which is generally a problem for decision trees.  \n",
    "  \n",
    "### KNN Algorithm  \n",
    "KNN is one of the most popular supervised learning algorithm which can be used for classification as well as regression.  \n",
    "It is a lazy learner who does all the work at runtime.  \n",
    "KNN works on feature similarity for classification of data,   \n",
    "i.e. the classification of data will depend on the features closely relating to the data and the distance between the features determines what classification of data should be as per the features.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Multinomial Naive Bayes\", MultinomialNB()),\n",
    "    (\"Gaussian Naive Bayes\", GaussianNB()),\n",
    "    (\"Random Forest Classifier\", RandomForestClassifier(n_estimators=100, max_depth=2)),\n",
    "    (\"KNN Algorithm\", KNeighborsClassifier(algorithm=\"brute\", n_neighbors=3)),\n",
    "    # (\"SVM\", SVC(gamma=\"scale\")),\n",
    "    # (\"LDA\", LinearDiscriminantAnalysis()),\n",
    "    # (\"Decision Tree Classifier\", DecisionTreeClassifier(label=TrainLabel)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "In KNN and Random forest classifier, There is the number of parameters that can define the scope of the algorithm.  \n",
    "e.g. :  \n",
    "**For KNN**, there are 2 main parameters: number of neighbors and distance metric power  \n",
    "number of neighbors - the number of closest neighbors to consider while classifying the data point  \n",
    "Power - to identify the distance metric, 1 => Minkowski Distance , 2 => Euclidian distance etc.  \n",
    "  \n",
    "**For Random forest classifier**, We have estimators, max features, depth and criteria  \n",
    "Estimator - The number of trees to consider  \n",
    "max features - the maximum number of features to consider while looking for split  \n",
    "depth - the depth of each tree to explore  \n",
    "criteria - for quality of the split  \n",
    "  \n",
    "Tuning these hyper-parameters can drastically increase the accuracy of the model.  \n",
    "  \n",
    "I have done hyperparameter testing using **Grid Search Cross fold Validation**, in which we provide the search space   in which best hyper parameters can be observed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter Testing ###\n",
    "# knn = KNeighborsClassifier()\n",
    "# scores = model_selection.cross_val_score(knn, X, TrainLabel, cv=10)\n",
    "# print(scores.mean())\n",
    "# param_grid = [{\"n_neighbors\": list(range(1, 10)), \"p\": [1, 2, 3, 4, 5]}]\n",
    "# clf = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, n_jobs=-1)\n",
    "# clf.fit(X, TrainLabel)\n",
    "# print(\"\\n Best parameters set found on development set:\")\n",
    "# print(clf.best_params_, \"with a score of \", clf.best_score_)\n",
    "\n",
    "# rfc=RandomForestClassifier(random_state=42)\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 500],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'max_depth' : [1,2,3,4,5],\n",
    "#     'criterion' :['gini', 'entropy']\n",
    "# }\n",
    "# CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "# CV_rfc.fit(X, TrainLabel)\n",
    "# print(CV_rfc.best_params_,\"with a score of \", CV_rfc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, For each model we have trained it aginst train label and predicted the score of classification against test label.  \n",
    "We have used plt.bar for Bar graph representation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes : 0.5042058386937159\n",
      "Accuracy of Gaussian Naive Bayes : 0.5017318159327065\n",
      "Accuracy of Random Forest Classifier : 0.49529935675408215\n",
      "Accuracy of KNN Algorithm : 0.5049480455220188\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, model in models:\n",
    "\n",
    "    model.fit(X, TrainLabel)\n",
    "\n",
    "    score = model.score(Xtest, TestLabel)\n",
    "    \n",
    "    plt.bar(name, score)\n",
    "    print(\"Accuracy of\", name, \":\", score)\n",
    "\n",
    "plt.ylim(ymin=0.45, ymax=0.55)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Output : \n",
    "Accuracy of Multinomial Naive Bayes : 0.5042058386937159  \n",
    "Accuracy of Gaussian Naive Bayes : 0.5017318159327065  \n",
    "Accuracy of Random Forest Classifier : 0.49925779317169716  \n",
    "Accuracy of KNN Algorithm : 0.5049480455220188  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Task A against different Models :   \n",
    "\n",
    "\n",
    "| Best Performance |     Worst Performance    |\n",
    "|:----------------:|:------------------------:|\n",
    "|   KNN Algorithm  | Random Forest Classifier |\n",
    "|      50.49 %     |          49.92 %         |\n",
    "    \n",
    "As we can see from the graph, The accuracy between the models does not differ much (hardly by 1-2 %).  \n",
    "Still, The KNN algorithm performs best out of the 4 models whereas Random forest performs the worst.  \n",
    "  \n",
    "\n",
    "| Mean Accuracy | 50.42 % |\n",
    "|---------------|---------|    \n",
    "  \n",
    "    \n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Explanation (Multi-Choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In task B, I have implemented 2 approaches :**\n",
    "1. Using Text classification   \n",
    "2. Using N-gram language model    \n",
    "  \n",
    "In the text classification, I have followed a similar process as the first problem and used 4 models for comparison of accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Handling : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatadf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskB_data_all.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trainLabeldf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskB_answers_all.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "trialDatadf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskB_trial_data.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trialLabeldf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskB_trial_answer.csv\", encoding=\"utf-8\", header=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of label\n",
    "trainLabeldf.rename(columns={0: \"id\", 1: \"answer\"}, inplace=True)\n",
    "trialLabeldf.rename(columns={0: \"id\", 1: \"answer\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have used Label Encoder, which converts the labels/classes with numberic values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "trainLabeldf[\"label\"] = LE.fit_transform(trainLabeldf[\"answer\"])\n",
    "trialLabeldf[\"label\"] = LE.fit_transform(trialLabeldf[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge label and data\n",
    "trainDatadf = trainDatadf.merge(trainLabeldf, on=\"id\")\n",
    "trialDatadf = trialDatadf.merge(trialLabeldf, on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have taken the Correct list of answers using the labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctData = []\n",
    "correctLabel = []\n",
    "\n",
    "for index, row in trainDatadf.iterrows():\n",
    "    if row[\"answer\"] == \"A\":\n",
    "        correctData.append(str(row[\"OptionA\"]))\n",
    "        correctLabel.append(row[\"label\"])\n",
    "\n",
    "    elif row[\"answer\"] == \"B\":\n",
    "        correctData.append(str(row[\"OptionB\"]))\n",
    "        correctLabel.append(row[\"label\"])\n",
    "\n",
    "    elif row[\"answer\"] == \"C\":\n",
    "        correctData.append(str(row[\"OptionC\"]))\n",
    "        correctLabel.append(row[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the unseen data (Test Data), We have to take both right and wrong answers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctDataTrial = []\n",
    "wrongtDataTrial = []\n",
    "correctTrialLabel = []\n",
    "wrongTrialLabel = []\n",
    "for index, row in trialDatadf.iterrows():\n",
    "    if row[\"answer\"] == \"A\":\n",
    "        correctDataTrial.append(str(row[\"OptionA\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"OptionB\"]))\n",
    "        wrongtDataTrial.append(str(row[\"OptionC\"]))\n",
    "        wrongTrialLabel.extend((row[\"label\"], row[\"label\"]))\n",
    "    elif row[\"answer\"] == \"B\":\n",
    "        correctDataTrial.append(str(row[\"OptionB\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"OptionA\"]))\n",
    "        wrongtDataTrial.append(str(row[\"OptionC\"]))\n",
    "        wrongTrialLabel.extend((row[\"label\"], row[\"label\"]))\n",
    "    elif row[\"answer\"] == \"C\":\n",
    "        correctDataTrial.append(str(row[\"OptionC\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"OptionB\"]))\n",
    "        wrongtDataTrial.append(str(row[\"OptionC\"]))\n",
    "        wrongTrialLabel.extend((row[\"label\"], row[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the numpy array for both Train and test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = np.array([*correctData]).flatten()\n",
    "TrainLabel = np.array([*correctLabel]).flatten()\n",
    "\n",
    "TestData = np.array([*correctDataTrial, *wrongtDataTrial]).flatten()\n",
    "TestLabel = np.array([*correctTrialLabel, *wrongTrialLabel]).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dimensions and length of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking the Dimensions ##\n",
    "# print(len(correctData), len(correctLabel))\n",
    "# print(len(correctDataTrial), len(correctTrialLabel))\n",
    "# print(len(wrongtData), len(wrongLabel))\n",
    "# print(len(wrongtDataTrial), len(wrongTrialLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing and Feature extraction using TF-IDF Vectorizer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\", ngram_range=(1, 3), max_features=28461\n",
    ")\n",
    "\n",
    "# print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "X = vectorizer.fit_transform(TrainData).toarray()\n",
    "\n",
    "Xtest = vectorizer.fit_transform(TestData).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used four models for Accuracy comparison.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Multinomial Naive Bayes\", MultinomialNB()),\n",
    "    (\"Gaussian Naive Bayes\", GaussianNB()),\n",
    "    (\"Random Forest Classifier\", RandomForestClassifier(n_estimators=100, max_depth=2)),\n",
    "    (\"KNN Algorithm\", KNeighborsClassifier(algorithm=\"brute\", n_neighbors=3)),\n",
    "    # (\"SVM\", SVC(gamma=\"scale\")),\n",
    "    # (\"LDA\", LinearDiscriminantAnalysis()),\n",
    "    # (\"Decision Tree Classifier\", DecisionTreeClassifier(label=TrainLabel)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter Testing ###\n",
    "# knn = KNeighborsClassifier()\n",
    "# scores = model_selection.cross_val_score(knn, X, TrainLabel, cv=10)\n",
    "# print(scores.mean())\n",
    "# param_grid = [{\"n_neighbors\": list(range(1, 10)), \"p\": [1, 2, 3, 4, 5]}]\n",
    "# clf = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, n_jobs=-1)\n",
    "# clf.fit(X, TrainLabel)\n",
    "# print(\"\\n Best parameters set found on development set:\")\n",
    "# print(clf.best_params_, \"with a score of \", clf.best_score_)\n",
    "\n",
    "# rfc=RandomForestClassifier(random_state=42)\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 500],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'max_depth' : [1,2,3,4,5],\n",
    "#     'criterion' :['gini', 'entropy']\n",
    "# }\n",
    "# CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "# CV_rfc.fit(X, TrainLabel)\n",
    "# print(CV_rfc.best_params_,\"with a score of \", CV_rfc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and calculate the score for each model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes : 0.3420748804222332\n",
      "Accuracy of Gaussian Naive Bayes : 0.34553851228764637\n",
      "Accuracy of Random Forest Classifier : 0.32690087415470886\n",
      "Accuracy of KNN Algorithm : 0.33250865907966354\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, model in models:\n",
    "\n",
    "    model.fit(X, TrainLabel)\n",
    "\n",
    "    score = model.score(Xtest, TestLabel)\n",
    "    \n",
    "    plt2.bar(name, score)\n",
    "    print(\"Accuracy of\", name, \":\", score)\n",
    "    \n",
    "plt2.ylim(ymin=0.30, ymax=0.40)\n",
    "plt2.xticks(rotation=45)\n",
    "plt2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output :   \n",
    "Accuracy of Multinomial Naive Bayes : 0.3420748804222332  \n",
    "Accuracy of Gaussian Naive Bayes : 0.34553851228764637  \n",
    "Accuracy of Random Forest Classifier : 0.32657100445324094  \n",
    "Accuracy of KNN Algorithm : 0.33250865907966354  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Task B against different Models :   \n",
    "  \n",
    "    \n",
    "\n",
    "|   Best Performance   |     Worst Performance    |\n",
    "|:--------------------:|:------------------------:|\n",
    "| Gaussian Naive Bayes | Random Forest Classifier |\n",
    "|        34.55 %       |          32.65 %         |  \n",
    "  \n",
    "    \n",
    "As we can see from the graph, The accuracy between the models lies somewhere between 32 to 35 %.  \n",
    "The Gaussian Navie Bayes algorithm performs best out of the 4 models whereas Random forest performs the worst.  \n",
    "  \n",
    "\n",
    "| Mean Accuracy | 33.66 % |\n",
    "|---------------|---------|    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using N-gram language model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than text classification, I have also tried to find the Accuracy with N-Gram language model for Task B,  \n",
    "But I have not completed the code yet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatadf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskB_data_all.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trainLabeldf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskB_answers_all.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "trialDatadf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskB_trial_data.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trialLabeldf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskB_trial_answer.csv\", encoding=\"utf-8\", header=None\n",
    ")\n",
    "\n",
    "# name columns of label\n",
    "trainLabeldf.rename(columns={0: \"id\", 1: \"answer\"}, inplace=True)\n",
    "trialLabeldf.rename(columns={0: \"id\", 1: \"answer\"}, inplace=True)\n",
    "\n",
    "\n",
    "LE = LabelEncoder()\n",
    "trainLabeldf[\"label\"] = LE.fit_transform(trainLabeldf[\"answer\"])\n",
    "trialLabeldf[\"label\"] = LE.fit_transform(trialLabeldf[\"answer\"])\n",
    "\n",
    "\n",
    "# merge label and data\n",
    "trainDatadf = trainDatadf.merge(trainLabeldf, on=\"id\")\n",
    "trialDatadf = trialDatadf.merge(trialLabeldf, on=\"id\")\n",
    "\n",
    "\n",
    "correctData = []\n",
    "correctLabel = []\n",
    "\n",
    "for index, row in trainDatadf.iterrows():\n",
    "    if row[\"answer\"] == \"A\":\n",
    "        correctData.append(str(row[\"OptionA\"]))\n",
    "        correctLabel.append(row[\"label\"])\n",
    "\n",
    "    elif row[\"answer\"] == \"B\":\n",
    "        correctData.append(str(row[\"OptionB\"]))\n",
    "        correctLabel.append(row[\"label\"])\n",
    "\n",
    "    elif row[\"answer\"] == \"C\":\n",
    "        correctData.append(str(row[\"OptionC\"]))\n",
    "        correctLabel.append(row[\"label\"])\n",
    "\n",
    "\n",
    "# print(len(correctData), len(correctLabel))\n",
    "\n",
    "correctDataTrial = []\n",
    "wrongtDataTrial = []\n",
    "correctTrialLabel = []\n",
    "wrongTrialLabel = []\n",
    "for index, row in trialDatadf.iterrows():\n",
    "    if row[\"answer\"] == \"A\":\n",
    "        correctDataTrial.append(str(row[\"OptionA\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"OptionB\"]))\n",
    "        wrongtDataTrial.append(str(row[\"OptionC\"]))\n",
    "        wrongTrialLabel.extend((row[\"label\"], row[\"label\"]))\n",
    "    elif row[\"answer\"] == \"B\":\n",
    "        correctDataTrial.append(str(row[\"OptionB\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"OptionA\"]))\n",
    "        wrongtDataTrial.append(str(row[\"OptionC\"]))\n",
    "        wrongTrialLabel.extend((row[\"label\"], row[\"label\"]))\n",
    "    elif row[\"answer\"] == \"C\":\n",
    "        correctDataTrial.append(str(row[\"OptionC\"]))\n",
    "        correctTrialLabel.append(row[\"label\"])\n",
    "\n",
    "        wrongtDataTrial.append(str(row[\"OptionB\"]))\n",
    "        wrongtDataTrial.append(str(row[\"OptionC\"]))\n",
    "        wrongTrialLabel.extend((row[\"label\"], row[\"label\"]))\n",
    "\n",
    "\n",
    "text = \" \".join(correctData)\n",
    "tokenized_text = [\n",
    "    list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(text)\n",
    "]\n",
    "\n",
    "\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "\n",
    "model = MLE(n)\n",
    "\n",
    "model.fit(train_data, padded_sents)\n",
    "\n",
    "# print(model.counts['cereal'])\n",
    "for index, row in trialDatadf.iterrows():\n",
    "    # print(model.score(row[\"sent0\"].split()))\n",
    "\n",
    "    tokenized_optA = sent_tokenize(row[\"OptionA\"])\n",
    "    print(model.score(tokenized_optA))\n",
    "    tokenized_optB = sent_tokenize(row[\"OptionB\"])\n",
    "    print(model.score(tokenized_optB))\n",
    "    tokenized_optC = sent_tokenize(row[\"OptionC\"])\n",
    "    print(model.score(tokenized_optC))\n",
    "\n",
    "# print(trainDatadf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Explanation (Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third task , I have tried 2 approaches:    \n",
    "1. Word Level Neural Language model with LSTM.   \n",
    "2. BERT language model for generation of text.  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-Level Neural Language model with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Imports :\n",
    "  \n",
    "Here, I have used Keras library and Tensarflow in the backend.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from pickle import dump, load\n",
    "from random import randint\n",
    "\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Handling :  \n",
    "  \n",
    "In the snippet below, I have used 3 functions :  \n",
    "1. load_doc : for loading the document in memory.  \n",
    "2. save_doc : for saving the respective tokens in the file.  \n",
    "3. clean_doc: for cleaning the data(lowercase,whitespace,special characters) and tokenizing the cleaned data.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, \"r\")\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace(\"--\", \" \")\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = \"\\n\".join(lines)\n",
    "    file = open(filename, \"w\")\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver code for Tokenizing and sequence generation :  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Driver Code ##\n",
    "\n",
    "# load document\n",
    "in_filename = \"Training  Data/Training  Data/subtaskC_answers_all.csv\"\n",
    "doc = load_doc(in_filename)\n",
    "\n",
    "\n",
    "# clean document\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:10])\n",
    "print(\"Total Tokens: %d\" % len(tokens))\n",
    "print(\"Unique Tokens: %d\" % len(set(tokens)))\n",
    "\n",
    "# organize into sequences of tokens\n",
    "length = 10 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i - length : i]\n",
    "    # convert into a line\n",
    "    line = \" \".join(seq)\n",
    "    # store\n",
    "    sequences.append(line)\n",
    "print(\"Total Sequences: %d\" % len(sequences))\n",
    "\n",
    "# save sequences to file\n",
    "out_filename = \"sequenced_Data.txt\"\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the file in memory and splitting the sentences by nextline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "in_filename = \"sequenced_Data.txt\"\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the thes lines from text using fit_on_texts method of tokenizer and generate the sequences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing and conversion of sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "# generating a vocab size\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the sequence generated to input and our sequences, and converting the output to_categorical which converts the vectors(classes) into binary matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a sequencial Model and using inbuild model LSTM for fitting the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM (Long Short Term Memory networks):  \n",
    "Special kind of RNN which are cabpable of learning long-term dependacies.   \n",
    "LSTM avoid the issue of long term dependancies which is sometimes necessary if we need to get recent information for the present task.  \n",
    "LSTM works on chain like structure containing multiple neural networks inside which works on cell state.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "#adding the vocab with vector space as 10, which we have specified in the sequence\n",
    "model.add(Embedding(vocab_size, 10, input_length=seq_length))\n",
    "\n",
    "#defininf the LSTM model with memory cells 100\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "\n",
    "#adding another layer of LSTM with 100 memory cells\n",
    "model.add(LSTM(100))\n",
    "\n",
    "#dense connectionwith 100 neurons\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "\n",
    "#softmax for normalising the probabilities\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=10)\n",
    "\n",
    "# save the model(model.h5) in current directory\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tokenizer\n",
    "dump(tokenizer, open(\"tokenizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "# load cleaned text sequences\n",
    "in_filename = \"sequenced_Data.txt\"\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split(\"\\n\")\n",
    "seq_length = len(lines[0].split()) - 1\n",
    "\n",
    "# load the model\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = load(open(\"tokenizer.pkl\", \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of sequence from language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating=\"pre\")\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += \" \" + out_word\n",
    "        result.append(out_word)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a random seed and generate a sequence from the method above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0, len(lines))]\n",
    "print(seed_text + \"\\n\")\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output : \n",
    "\n",
    "212049/212049 [==============================] - 602s 3ms/step - loss: 6.4921 - acc: 0.0520    \n",
    "Epoch 2/5  \n",
    "212049/212049 [==============================] - 624s 3ms/step - loss: 6.2987 - acc: 0.1210  \n",
    "Epoch 3/5  \n",
    "212049/212049 [==============================] - 701s 3ms/step - loss: 5.9302 - acc: 0.1536  \n",
    "Epoch 4/5  \n",
    "212049/212049 [==============================] - 769s 3ms/step - loss: 5.7015 - acc: 0.1689  \n",
    "Epoch 5/5  \n",
    "212049/212049 [==============================] - 830s 4ms/step - loss: 5.6190 - acc: 0.1761  \n",
    "dry insects are dictionaries language sharing is boards insect dry cleaners needs the shop naturally cow europe metal has limited space socks relatives is a continent high blood pressure cannot  \n",
    "  \n",
    "insect the dry cleaners is dry soil language   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT (Bidirectional Encoder Representations from Transformers) :  \n",
    "#### What is BERT ?  \n",
    "BERT is a language model based on Transformer architecture.  \n",
    "It is used to pre-train the unlabelled text from both the directions instead of the one-directional approach which we use in most of the models.  \n",
    "i.e. It adds both the left and right side features and calculates conditional dependancy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertMaskedLM = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatadf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskC_data_all.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trainLabeldf = pd.read_csv(\n",
    "    \"Training  Data/Training  Data/subtaskC_answers_all.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "trialDatadf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskC_trial_data.csv\", encoding=\"utf-8\"\n",
    ")\n",
    "trialLabeldf = pd.read_csv(\n",
    "    \"Trial Data/Trial Data/taskC_trial_references.csv\", encoding=\"utf-8\", header=None\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabeldf.rename(\n",
    "    columns={0: \"id\", 1: \"answerA\", 2: \"answerB\", 3: \"answerC\"}, inplace=True\n",
    ")\n",
    "trialLabeldf.rename(\n",
    "    columns={0: \"id\", 1: \"answerA\", 2: \"answerB\", 3: \"answerC\"}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(sentence):\n",
    "    tokenize_input = tokenizer.tokenize(sentence)\n",
    "    tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "    predictions = bertMaskedLM(tensor_input)\n",
    "    loss_fct = torch.nn.CrossEntropyLoss()\n",
    "    loss = loss_fct(predictions.squeeze(), tensor_input.squeeze()).data\n",
    "    return math.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputArr = (trainDatadf[\"FalseSent\"]).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT code is not completed due to time limitation on my part.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
